{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
   "metadata": {},
   "source": [
    "# SQL query from table names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
   "metadata": {
    "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
   },
   "source": [
    "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
   "metadata": {
    "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
   "metadata": {
    "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_OAI(user_message):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY\n",
    "    context = []\n",
    "    context.append({'role':'system', \"content\": user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=context,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
   "metadata": {
    "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
    "outputId": "61068bf0-41e3-40d9-b453-b76da5b0f086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      table                                         definition\n",
      "0  shipping  Shipping details: shipping method, cost, and d...\n",
      "1  payments  Payment details: payment method, amount paid, ...\n",
      "2   reviews  Product reviews: customer rating, comments, an...\n"
     ]
    }
   ],
   "source": [
    "#Definition of the tables.\n",
    "import pandas as pd\n",
    "\n",
    "# Table and definitions sample\n",
    "data = {'table': ['shipping', 'payments', 'reviews'],\n",
    "        'definition': ['Shipping details: shipping method, cost, and delivery time',\n",
    "                       'Payment details: payment method, amount paid, and payment status',\n",
    "                       'Product reviews: customer rating, comments, and review date']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
   "metadata": {
    "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
   },
   "outputs": [],
   "source": [
    "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
   "metadata": {
    "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
    "outputId": "c1f3aab1-5f26-48fe-fcf9-3780120f5aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shipping: Shipping details: shipping method, cost, and delivery time\n",
      "payments: Payment details: payment method, amount paid, and payment status\n",
      "reviews: Product reviews: customer rating, comments, and review date\n"
     ]
    }
   ],
   "source": [
    "print(text_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
   "metadata": {
    "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
   },
   "outputs": [],
   "source": [
    "prompt_question_tables = \"\"\"\n",
    "Given the following tables and their content definitions,\n",
    "###Tables\n",
    "{tables}\n",
    "\n",
    "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
    "Return the table names in a json format.\n",
    "###User Questyion:\n",
    "{question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
   "metadata": {
    "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
   },
   "outputs": [],
   "source": [
    "#Creating the prompt, with the user questions and the tables definitions.\n",
    "pqt1 = prompt_question_tables.format(tables=text_tables, question=\"What is the average shipping cost for orders delivered via express method?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
   "metadata": {
    "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
    "outputId": "9924022c-7b2b-4ec8-e2c2-75bc1c745151",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"shipping\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
   "metadata": {
    "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
   },
   "outputs": [],
   "source": [
    "pqt3 =prompt_question_tables.format(tables=text_tables,\n",
    "                                     question=\"How many reviews did each product receive, and what is the average rating per product?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
   "metadata": {
    "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
    "outputId": "81d77115-9cad-4284-a228-5368bb9aa6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"tables\": [\"reviews\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
   "metadata": {
    "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try a few versions if you have time\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85db0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"payments\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "pqt4 = prompt_question_tables.format(tables=text_tables,\n",
    "                                     question=\"What payment methods were used the most, and how much total was paid using each method?\")\n",
    "print(return_OAI(pqt4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56a7788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"reviews\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "pqt5 = prompt_question_tables.format(tables=text_tables,\n",
    "                                     question=\"Which products received the highest ratings and what were the most common comments associated with them?\")\n",
    "print(return_OAI(pqt5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d88d4a",
   "metadata": {},
   "source": [
    "Summary Report: SQL Query from Table Names Using GPT-3.5-Turbo\n",
    "Objective:\n",
    "This experiment aimed to assess whether GPT-3.5-Turbo can accurately identify the relevant tables required for SQL queries using only table names and brief descriptions. The approach involved structured prompts, feeding the model with tabular metadata, and evaluating its responses for accuracy.\n",
    "\n",
    "Findings:\n",
    "Effective Scenarios:\n",
    " Accurate Table Selection: When table names and descriptions clearly aligned with the query, GPT-3.5-Turbo successfully identified the necessary tables.\n",
    "Structured Prompts Yield Better Results: Well-defined instructions and formatting significantly improved accuracy and consistency.\n",
    "Handling Multi-Table Queries: The model correctly inferred relevant tables when handling queries like determining the fastest shipping method with the lowest costâ€”identifying the shipping table as essential.\n",
    "Inference in Ambiguous Cases: When the query was vague (e.g., identifying necessary tables without explicit conditions), the model still inferred key relationships between tables like payments, reviews, and shipping to generate reasonable responses.\n",
    "\n",
    "Challenging Scenarios:\n",
    " Hallucinations: In some cases, the model included irrelevant tables that were not needed for the specific query.\n",
    " Over-Inclusion of Tables: The model occasionally overcompensated by selecting more tables than necessary (e.g., including the reviews table when a query was solely about shipping).\n",
    " Table Omission in Edge Cases: For certain complex queries involving filtering (e.g., finding the best-rated shipping provider based on past reviews), the model sometimes omitted relevant tables.\n",
    " Prompt Sensitivity: Small changes in how the query was phrased affected consistency, sometimes leading to different sets of selected tables for similar questions.\n",
    "\n",
    "Key Learnings:\n",
    " Prompt Optimization is Crucial: The quality of the prompt directly impacts the modelâ€™s ability to identify correct tables.\n",
    " Explicit Table Descriptions Improve Accuracy: Vague descriptions result in hallucinations or omissionsâ€”clearer metadata helps guide the model.\n",
    " Iterative Testing is Beneficial: Running multiple variations of the same query can help refine the prompt structure for better results.\n",
    " Explicit Table Relationships Help: Clearly stating how tables are linked in the database schema improves accuracy in multi-table queries.\n",
    " GPT-3.5-Turbo's Relational Reasoning is Limited: While it can infer relationships based on descriptions, it does not inherently understand SQL schema dependencies.\n",
    "\n",
    "Future Considerations:\n",
    " Improve Table Definitions: Adding more context-rich, detailed descriptions will enhance accuracy.\n",
    " Provide Contextual Examples: Including sample queries with expected table selections can improve the modelâ€™s ability to generalize correctly.\n",
    " Manually Validate Outputs: Cross-checking model predictions against actual database schemas can help detect hallucinations.\n",
    " Fine-Tune for SQL Tasks: Training a specialized model for database-related tasks could improve precision.\n",
    " Explicitly Prioritize Relationships: Designing prompts that highlight inter-table relationships will aid in handling complex queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0382db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AI_Enginnring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
